{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, re, contractions\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "model_chat = \"gpt-3.5-turbo\"    # Model that powers the ChatGPT\n",
    "model_davinci = \"text-davinci-003\"  # Best model\n",
    "model_curie = \"text-curie-001\"  # Second-best, but faster (May be suitable for sentiment classification)\n",
    "\n",
    "input_path = \"../data/samples/\"\n",
    "output_path = \"../data/labelled/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load slang dictionary\n",
    "slang_path = \"../data/slang.json\"\n",
    "with open(slang_path, \"r\") as f:\n",
    "    slang_dicts = json.load(f)\n",
    "    for slang in slang_dicts:\n",
    "        contractions.add(slang, slang_dicts[slang])\n",
    "\n",
    "def preprocess(row):\n",
    "    content = row[\"content\"]\n",
    "    # Remove Aliases of Usernames and URLs in tweets\n",
    "    pattern = r\"\\n+|((?:USERNAME|URL)_\\d*\\s*)\"\n",
    "    content = re.sub(pattern, \"\", content)\n",
    "    # Convert contractions to full form\n",
    "    content = contractions.fix(content)\n",
    "    return {'content': content}\n",
    "\n",
    "def insert_tweets(tweets_list):\n",
    "    result = \"\"\n",
    "    for i, tweet in enumerate(tweets_list):\n",
    "        result += f\"{i}.\\n{tweet['content']}\\n\"\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_filename = \"samples_230227-230308_#577.json\"\n",
    "# with open(\"/home/p11333at/nlp-project/data/raw/tweets_230227_#63481.json\", \"r\") as f:\n",
    "with open(input_path+input_filename, \"r\") as f:\n",
    "    data = f.readlines()\n",
    "    data = [json.loads(line) for line in data]\n",
    "\n",
    "preprocessed_data = [preprocess(row) for row in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TextBlob\n",
    "\n",
    "def get_textblob_sentiment(tweet):\n",
    "    sen = TextBlob(tweet[\"content\"])\n",
    "    if sen.sentiment.polarity > 0:\n",
    "        return 2    # Positive\n",
    "    elif sen.sentiment.polarity < 0:\n",
    "        return 0    # Negative\n",
    "    else:\n",
    "        return 1    # Neutral\n",
    "\n",
    "textblob_sentiments = [get_textblob_sentiment(tweet) for tweet in preprocessed_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VADER\n",
    "\n",
    "def get_vader_sentiment(tweet):\n",
    "    # Create a SentimentIntensityAnalyzer object.\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    " \n",
    "    # polarity_scores method of SentimentIntensityAnalyzer\n",
    "    sentiment_dict = sid_obj.polarity_scores(tweet['content'])\n",
    " \n",
    "    # decide sentiment as positive, negative and neutral\n",
    "    if sentiment_dict['compound'] >= 0.05 :\n",
    "        return 2    # Positive\n",
    "    elif sentiment_dict['compound'] <= - 0.05 :\n",
    "        return 0    # Negative\n",
    "    else :\n",
    "        return 1    # Neutral\n",
    "\n",
    "vader_sentiments = [get_vader_sentiment(tweet) for tweet in preprocessed_data]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentiment(tweets_list):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an assistant that classify the sentiment in tweets, using 0, 1, 2 to represent negative, neutral and positive respectively. The result must be json format with curly brackets, and property name must be the given index number enclosed in double quotes.\"},\n",
    "        {\"role\": \"user\", \"content\": f'Classify the sentiment of the following tweets: \"{insert_tweets(tweets_list)}\"'}\n",
    "    ]\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model_chat,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    # results = json.loads(response['choices'][0]['message']['content'])\n",
    "    results = response['choices'][0]['message']['content']\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n    \"0\": 2,\\n    \"1\": 0,\\n    \"2\": 1,\\n    \"3\": 2,\\n    \"4\": 0,\\n    \"5\": 0,\\n    \"6\": 2,\\n    \"7\": 0,\\n    \"8\": 0,\\n    \"9\": 2,\\n    \"10\": 0,\\n    \"11\": 0,\\n    \"12\": 1,\\n    \"13\": 0,\\n    \"14\": 1,\\n    \"15\": 0,\\n    \"16\": 1\\n}'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [{'content': \"Iâ€™m on day 5 of COVID and overall feeling better BUT WHEN DO MY HIPS STOP HURTING????\"}]\n",
    "temp = classify_sentiment(preprocessed_data[:17])\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"0\": 2,\n",
      "    \"1\": 0,\n",
      "    \"2\": 1,\n",
      "    \"3\": 2,\n",
      "    \"4\": 0,\n",
      "    \"5\": 0,\n",
      "    \"6\": 2,\n",
      "    \"7\": 0,\n",
      "    \"8\": 0,\n",
      "    \"9\": 2,\n",
      "    \"10\": 0,\n",
      "    \"11\": 0,\n",
      "    \"12\": 1,\n",
      "    \"13\": 0,\n",
      "    \"14\": 1,\n",
      "    \"15\": 0,\n",
      "    \"16\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(temp) #1012002002 00102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = f'''Classify the sentiment in these tweets, using 0, 1, 2 to represent positive, neutral and negative respectively. The result must be json format with curly brackets, and property name must be the given index number enclosed in double quotes.\n",
    "\n",
    "# {insert_tweets(preprocessed_data[:5])}\n",
    "\n",
    "# The result should be json format.\n",
    "# '''\n",
    "\n",
    "# response = openai.Completion.create(\n",
    "#       model=model_davinci,\n",
    "#       prompt=prompt,\n",
    "#       temperature=0,\n",
    "#       max_tokens=500\n",
    "#     )\n",
    "\n",
    "# results = json.loads(response[\"choices\"][0][\"text\"])\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of data: 577\n",
      "Number each time: 40 \n",
      "Iteration: 15 \n",
      "Last iteration's num: 17\n",
      "577 = 14 * 40 + 17\n",
      "\n",
      "[0, 40, 80, 120, 160, 200, 240, 280, 320, 360, 400, 440, 480, 520, 560, 577]\n"
     ]
    }
   ],
   "source": [
    "print(f'The length of data: {len(preprocessed_data)}')\n",
    "\n",
    "num_each_time = 40\n",
    "\n",
    "iteration, last_num_tweets = len(preprocessed_data)//num_each_time+1, len(preprocessed_data)%num_each_time\n",
    "print(f\"Number each time: {num_each_time} \\nIteration: {iteration} \\nLast iteration's num: {last_num_tweets}\")\n",
    "print(f'{len(preprocessed_data)} = {iteration-1} * {num_each_time} + {last_num_tweets}')\n",
    "\n",
    "\n",
    "index = [ i*num_each_time for i in range(iteration)]\n",
    "\n",
    "if last_num_tweets > 0:\n",
    "    index += [len(preprocessed_data)]\n",
    "\n",
    "print()\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the raw results (string format)\n",
    "results = []\n",
    "for i in range(len(index)-1):\n",
    "    l, r = index[i], index[i+1]\n",
    "    slice_tweets_list = preprocessed_data[l:r]\n",
    "    print(f\"{l} -> {r}  (Expected: {len(slice_tweets_list)})\", end=\"\\r\")\n",
    "    res = classify_sentiment(slice_tweets_list)\n",
    "    # print(f\"  Actual: {len(res)}\")\n",
    "    results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = []\n",
    "for i in range(len(results)):\n",
    "    # Convert the raw results to json format\n",
    "    # Do the convertion here to avoid openai returning response in wrong format\n",
    "    json_res = json.loads(results[i])\n",
    "    # Retrieve the sentiment values\n",
    "    sentiments.extend(json_res.values())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store results in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiments = vader_sentiments\n",
    "for i in range(len(sentiments)):\n",
    "    sentiment = sentiments[i]\n",
    "\n",
    "    if 'sentiment' not in data[i].keys():\n",
    "        data[i].update(\n",
    "            { \"sentiment\" : {} }\n",
    "        )\n",
    "\n",
    "    data[i][\"sentiment\"].update(\n",
    "        { \"openai\" : sentiment }\n",
    "        # { \"vader\" : sentiment }\n",
    "        # { \"textblob\" : sentiment }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(output_path+\"chatgpt-labelled_\"+input_filename, \"w\") as f:\n",
    "# with open(output_path+\"trail_labelled_230227_#63481.json\", \"w\") as f:\n",
    "with open(output_path+\"labelled_\"+input_filename, \"w\") as f:\n",
    "    for line in data:\n",
    "        json.dump(line, f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d58456bdcf71a0aafcc61ee26750cc6fcc46b3f534d6a5983f0e2590bcc774fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
