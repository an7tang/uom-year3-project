{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentimen Annotator\n",
    "\n",
    "This notebook is used to annotate the sentiment of the tweets using TextBlob, VADER and OpenAI API.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, re, contractions\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "model_chat = \"gpt-3.5-turbo\"    # Model that powers the ChatGPT\n",
    "model_davinci = \"text-davinci-003\"  # Best model\n",
    "model_curie = \"text-curie-001\"  # Second-best, but faster (May be suitable for sentiment classification)\n",
    "\n",
    "input_path = \"../data/samples/\"\n",
    "output_path = \"../data/labelled/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load slang dictionary\n",
    "slang_path = \"../data/slang.json\"\n",
    "with open(slang_path, \"r\") as f:\n",
    "    slang_dicts = json.load(f)\n",
    "    for slang in slang_dicts:\n",
    "        contractions.add(slang, slang_dicts[slang])\n",
    "\n",
    "def preprocess(row):\n",
    "    content = row[\"content\"]\n",
    "    # Remove Aliases of Usernames and URLs in tweets\n",
    "    pattern_name = r\"\\n+|(USERNAME_\\d*\\s*)\"\n",
    "    content = re.sub(pattern_name, \"\", content)\n",
    "    pattern_url = r\"URL_\\d*\"\n",
    "    content = re.sub(pattern_url, \"URL\", content)\n",
    "    # Convert contractions to full form\n",
    "    content = contractions.fix(content)\n",
    "    return {'content': content}\n",
    "\n",
    "def insert_tweets(tweets_list):\n",
    "    result = \"\"\n",
    "    for i, tweet in enumerate(tweets_list):\n",
    "        result += f\"{i}.\\n{tweet['content']}\\n\"\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_filename = \"samples_230227-230308_#577.json\"\n",
    "with open(\"/home/p11333at/nlp-project/data/golden/positive_230227-230314_#153.json\", \"r\") as f:\n",
    "# with open(input_path+input_filename, \"r\") as f:\n",
    "    data = f.readlines()\n",
    "    data = [json.loads(line) for line in data]\n",
    "\n",
    "preprocessed_data = [preprocess(row) for row in data]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate sentiment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using `TextBlob`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TextBlob\n",
    "\n",
    "def get_textblob_sentiment(tweet):\n",
    "    sen = TextBlob(tweet[\"content\"])\n",
    "    if sen.sentiment.polarity > 0:\n",
    "        return 2    # Positive\n",
    "    elif sen.sentiment.polarity < 0:\n",
    "        return 0    # Negative\n",
    "    else:\n",
    "        return 1    # Neutral\n",
    "\n",
    "textblob_sentiments = [get_textblob_sentiment(tweet) for tweet in preprocessed_data]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using `VADER`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VADER\n",
    "\n",
    "def get_vader_sentiment(tweet):\n",
    "    # Create a SentimentIntensityAnalyzer object.\n",
    "    sid_obj = SentimentIntensityAnalyzer()\n",
    " \n",
    "    # polarity_scores method of SentimentIntensityAnalyzer\n",
    "    sentiment_dict = sid_obj.polarity_scores(tweet['content'])\n",
    " \n",
    "    # decide sentiment as positive, negative and neutral\n",
    "    if sentiment_dict['compound'] >= 0.05 :\n",
    "        return 2    # Positive\n",
    "    elif sentiment_dict['compound'] <= -0.05 :\n",
    "        return 0    # Negative\n",
    "    else :\n",
    "        return 1    # Neutral\n",
    "\n",
    "vader_sentiments = [get_vader_sentiment(tweet) for tweet in preprocessed_data]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `OpenAI`\n",
    "\n",
    "This is a little bit complicated than before two method."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `GPT-3.5 (ChatGPT)` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI GPT-3.5 (ChatGPT) model\n",
    "\n",
    "def classify_sentiment(tweets_list):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an assistant that classify the sentiment in tweets, using 0, 1, 2 to represent negative, neutral and positive respectively. The result must be json format with curly brackets, and property name must be the given index number enclosed in double quotes.\"},\n",
    "        {\"role\": \"user\", \"content\": f'Classify the sentiment of the following tweets: \"{insert_tweets(tweets_list)}\"'}\n",
    "    ]\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model_chat,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    # results = json.loads(response['choices'][0]['message']['content'])\n",
    "    results = response['choices'][0]['message']['content']\n",
    "    return results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Davinci` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI Davinci model\n",
    "\n",
    "# prompt = f'''Classify the sentiment in these tweets, using 0, 1, 2 to represent positive, neutral and negative respectively. The result must be json format with curly brackets, and property name must be the given index number enclosed in double quotes.\n",
    "\n",
    "# {insert_tweets(preprocessed_data[:5])}\n",
    "\n",
    "# The result should be json format.\n",
    "# '''\n",
    "\n",
    "# response = openai.Completion.create(\n",
    "#       model=model_davinci,\n",
    "#       prompt=prompt,\n",
    "#       temperature=0,\n",
    "#       max_tokens=500\n",
    "#     )\n",
    "\n",
    "# results = json.loads(response[\"choices\"][0][\"text\"])\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of data: 306\n",
      "Number each time: 40 \n",
      "Iteration: 8 \n",
      "Last iteration's num: 26\n",
      "306 = 7 * 40 + 26\n",
      "\n",
      "[0, 40, 80, 120, 160, 200, 240, 280, 306]\n"
     ]
    }
   ],
   "source": [
    "# Get the index\n",
    "\n",
    "print(f'The length of data: {len(preprocessed_data)}')\n",
    "\n",
    "num_each_time = 40\n",
    "\n",
    "iteration, last_num_tweets = len(preprocessed_data)//num_each_time+1, len(preprocessed_data)%num_each_time\n",
    "print(f\"Number each time: {num_each_time} \\nIteration: {iteration} \\nLast iteration's num: {last_num_tweets}\")\n",
    "print(f'{len(preprocessed_data)} = {iteration-1} * {num_each_time} + {last_num_tweets}')\n",
    "\n",
    "\n",
    "index = [ i*num_each_time for i in range(iteration)]\n",
    "\n",
    "if last_num_tweets > 0:\n",
    "    index += [len(preprocessed_data)]\n",
    "\n",
    "print()\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280 -> 306  (Expected: 26)\r"
     ]
    }
   ],
   "source": [
    "# Store the raw results (string format)\n",
    "\n",
    "results = []\n",
    "for i in range(len(index)-1):\n",
    "    l, r = index[i], index[i+1]\n",
    "    slice_tweets_list = preprocessed_data[l:r]\n",
    "    print(f\"{l} -> {r}  (Expected: {len(slice_tweets_list)})\", end=\"\\r\")\n",
    "    res = classify_sentiment(slice_tweets_list)\n",
    "    # print(f\"  Actual: {len(res)}\")\n",
    "    results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the raw results to json format\n",
    "# Do the convertion here to handle the error if openai API returns response in wrong format (sometimes happens)\n",
    "\n",
    "openai_sentiments = []\n",
    "for i in range(len(results)):\n",
    "    # Convert the raw results to json format\n",
    "    json_res = json.loads(results[i])\n",
    "    # Retrieve the sentiment values\n",
    "    openai_sentiments.extend(json_res.values())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store results in file\n",
    "\n",
    "As the three model may not be run at the same time, I wrote the code to store the result one by one.\n",
    "\n",
    "This needs to be manually setup. (Sorry for the inconvenience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = openai_sentiments\n",
    "# sentiments = vader_sentiments\n",
    "# sentiments = textblob_sentiments\n",
    "for i in range(len(sentiments)):\n",
    "    sentiment = sentiments[i]\n",
    "\n",
    "    if 'sentiment' not in data[i].keys():\n",
    "        data[i].update(\n",
    "            { \"sentiment\" : {} }\n",
    "        )\n",
    "\n",
    "    data[i][\"sentiment\"].update(\n",
    "        { \"openai\" : sentiment }\n",
    "        # { \"vader\" : sentiment }\n",
    "        # { \"textblob\" : sentiment }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder the data (Unnecessary)\n",
    "for line in data:\n",
    "    o = line['sentiment']['openai']\n",
    "    v = line['sentiment']['vader']\n",
    "    t = line['sentiment']['textblob']\n",
    "    h = line['sentiment']['human']\n",
    "\n",
    "    senti = {\"openai\": o, \"vader\": v, \"textblob\": t, \"human\": h}\n",
    "    line['sentiment'] = senti"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write into file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/p11333at/nlp-project/data/golden/new.json\", \"w\") as f:\n",
    "# with open(output_path+\"labelled_\"+input_filename, \"w\") as f:\n",
    "    for line in data:\n",
    "        json.dump(line, f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE END"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *(Please ignore the following part)*\n",
    "\n",
    "As the data annotation platform I'm using will change the JSON file structure, cells below are used to re-format JSON file after manually annotating the sentiment.\n",
    "\n",
    "### Manipulate data & file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_samples_path = \"/home/p11333at/nlp-project/data/golden/golden_230227-230308_#577.json\"\n",
    "\n",
    "with open(labelled_samples_path, 'r') as f:\n",
    "    data = f.readlines()\n",
    "    data = [json.loads(line) for line in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment = [line['sentiment'] for line in data if 'human' in line['sentiment'].keys()]\n",
    "sentiment = [line['sentiment'] for line in data]\n",
    "\n",
    "openai = np.array([s['openai'] for s in sentiment])\n",
    "vader = np.array([s['vader'] for s in sentiment])\n",
    "textblob = np.array([s['textblob'] for s in sentiment])\n",
    "human = np.array([s['human'] for s in sentiment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai (961, 361, 444)\n",
      "vader (886, 279, 601)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def count_labels(labels):\n",
    "    neg = np.count_nonzero(labels == 0)\n",
    "    neu = np.count_nonzero(labels == 1)\n",
    "    pos = np.count_nonzero(labels == 2)\n",
    "    return (neg, neu, pos)\n",
    "\n",
    "def calculate_accuracy(pred, true):\n",
    "    return np.count_nonzero(pred == true) / len(true)\n",
    "\n",
    "print(\"openai\", count_labels(openai))\n",
    "print(\"vader\", count_labels(vader))\n",
    "print(\"textblob\", count_labels(textblob))\n",
    "print(\"human\", count_labels(human))\n",
    "\n",
    "print()\n",
    "\n",
    "acc_openai = calculate_accuracy(openai, human)\n",
    "acc_vader = calculate_accuracy(vader, human)\n",
    "acc_textblob = calculate_accuracy(textblob, human)\n",
    "print(\"openai\", acc_openai)\n",
    "print(\"vader\", acc_vader)\n",
    "print(\"textblob\", acc_textblob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7644394110985278"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_accuracy(openai, vader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "383"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = (openai == 2).nonzero()[0]\n",
    "v = (vader == 2).nonzero()[0]\n",
    "\n",
    "double = np.intersect1d(o, v)\n",
    "len(double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = (openai == 2).nonzero()[0]\n",
    "v = (vader == 1).nonzero()[0]\n",
    "\n",
    "single_o = np.intersect1d(o, v)\n",
    "len(single_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = (openai == 1).nonzero()[0]\n",
    "v = (vader == 2).nonzero()[0]\n",
    "\n",
    "single_v = np.intersect1d(o, v)\n",
    "len(single_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(output_path+\"DOUBLE_positive_230227-230314_#383.json\", \"w\") as f:\n",
    "with open(output_path+\"SINGLE_positive_230227-230314_#101.json\", \"w\") as f:\n",
    "    for i in single_o:\n",
    "        json.dump(data[i], f)\n",
    "        f.write('\\n')\n",
    "    for i in single_v:\n",
    "        json.dump(data[i], f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert annotated data to formal format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelled_samples_path = \"/home/p11333at/nlp-project/data/golden/golden_230227-230308_#577.json\"\n",
    "labelled_samples_path = \"/home/p11333at/nlp-project/data/labelled/all.json\"\n",
    "\n",
    "with open(labelled_samples_path, 'r') as f:\n",
    "    data = f.readlines()\n",
    "    data = [json.loads(line) for line in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = []\n",
    "\n",
    "for i, line in enumerate(data):\n",
    "    creation_data = line['creation_date']\n",
    "    content = line['text']\n",
    "    sentiment = line['sentiment']\n",
    "    try:\n",
    "        label = line['label'][0]\n",
    "    except:\n",
    "        print(\"[index] :\", i)\n",
    "        print(content)\n",
    "        break\n",
    "\n",
    "    if label == 'Positive':\n",
    "        label = 2\n",
    "    # elif label == 'Neutral':\n",
    "    #     label = 1\n",
    "    # elif label == 'Negative':\n",
    "    #     label = 0\n",
    "    else:\n",
    "        continue\n",
    "        # raise Exception(\"Label is not valid\")\n",
    "    \n",
    "    sentiment.update({\"human\": label})\n",
    "\n",
    "    new_data.append({\n",
    "        \"creation_date\": creation_data,\n",
    "        \"content\": content,\n",
    "        \"sentiment\": sentiment,\n",
    "    })\n",
    "\n",
    "\n",
    "# with open(labelled_samples_path, 'r') as f:\n",
    "#     data = f.readlines()\n",
    "#     data = [json.loads(line) for line in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(labelled_samples_path, 'w') as f:\n",
    "with open(\"/home/p11333at/nlp-project/data/golden/positive_230227-230314_#156.json\", 'w') as f:\n",
    "    for line in new_data:\n",
    "        json.dump(line, f)\n",
    "        f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d58456bdcf71a0aafcc61ee26750cc6fcc46b3f534d6a5983f0e2590bcc774fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
