{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "model_davinci = \"text-davinci-003\"  # Best model\n",
    "model_curie = \"text-curie-001\"  # Second-best, but faster (May be suitable for sentiment classification)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_list = [\n",
    "    \"I can't stand homework\", \n",
    "    \"This sucks. I'm bored üò†\",\n",
    "    \"I can't wait for Halloween!!!\",\n",
    "    \"My cat is adorable ‚ù§Ô∏è‚ù§Ô∏è\",\n",
    "    \"I hate chocolate\",\n",
    "    \"I will go to the gym tomorrow\"\n",
    "]\n",
    "\n",
    "path_dataset = \"/Users/anqitang/code/uom/year3/year_project/dataset/raw/tweets_230212_#50_(230213-160745).json\"\n",
    "with open(path_dataset, \"r\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "def insert_tweets(tweets_list):\n",
    "    result = \"\"\n",
    "    for i, tweet in enumerate(tweets_list):\n",
    "        result += f\"{i}.\\n{tweet['content']}\\n\"\n",
    "    \n",
    "    return result\n",
    "\n",
    "# print(insert_tweets(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f'''Classify the sentiment in these tweets, using 1, 0, -1 to represent positive, neutral and negative respectively. The result should be json format.\n",
    "\n",
    "{insert_tweets(dataset)}\n",
    "\n",
    "The result should be json format.\n",
    "'''\n",
    "\n",
    "response = openai.Completion.create(\n",
    "      model=model_davinci,\n",
    "      prompt=prompt,\n",
    "      temperature=0,\n",
    "      max_tokens=500\n",
    "    )\n",
    "\n",
    "results = json.loads(response[\"choices\"][0][\"text\"])\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(results)):\n",
    "    sentiment = results[str(i)]\n",
    "\n",
    "    if 'sentiment' not in dataset[i].keys():\n",
    "        dataset[i].update(\n",
    "            { \"sentiment\" : {} }\n",
    "        )\n",
    "\n",
    "    dataset[i][\"sentiment\"].update(\n",
    "        { \"openai\" : sentiment }\n",
    "    )\n",
    "    \n",
    "\n",
    "with open(path_dataset, \"w\") as f:\n",
    "    json.dump(dataset, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d58456bdcf71a0aafcc61ee26750cc6fcc46b3f534d6a5983f0e2590bcc774fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
